{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09d33e9-608d-4aad-8ef3-dc7f2771d96d",
   "metadata": {},
   "source": [
    "# Basics of Linear Regression - House prices\n",
    "\n",
    "In this project, I aim to calculate the cost of house prices, using various factors such as size and number of bedrooms. I will first attempt to construct my own functions to implement the gradient descent algorithm using numpy, after which I can cross validate my predictions using scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b207558-3466-4ee9-bfe7-83ab191da33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15561484-60f2-45ef-97f6-132526707b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (sqft)</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Floors</th>\n",
       "      <th>Age</th>\n",
       "      <th>Price (1000USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>952.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>271.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>509.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Size (sqft)  Bedrooms  Floors   Age  Price (1000USD)\n",
       "0        952.0       2.0     1.0  65.0            271.5\n",
       "1       1244.0       3.0     1.0  64.0            300.0\n",
       "2       1947.0       3.0     2.0  17.0            509.8\n",
       "3       1725.0       3.0     2.0  42.0            394.0\n",
       "4       1959.0       3.0     2.0  15.0            540.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses = pd.read_csv(\"houses.txt\",header=None)\n",
    "houses.columns = ['Size (sqft)','Bedrooms','Floors','Age','Price (1000USD)']\n",
    "print(houses.shape)\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91bee0cf-cd4f-49d5-a198-60777727dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(houses[['Size (sqft)','Bedrooms','Floors','Age']])\n",
    "y = np.array(houses['Price (1000USD)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a39bb-817b-4b24-adc9-85c3b9a8b57a",
   "metadata": {},
   "source": [
    "## The cost function\n",
    "\n",
    "We first start by defining the cost function $J(\\mathbf{w},b)$, which is given by:\n",
    "\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 $$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b $$\n",
    "and $m$ is the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9694a628-5e78-4a98-ac92-6b07e568699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "# w is an ndarray (n,) and b is a scalar \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b\n",
    "        cost = cost + (f_wb_i - y[i])**2\n",
    "    cost = cost / (2 * m)    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f7630-ad45-4b46-8b76-40f4a4c2002a",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Now we can minimise this function to find optimal parameters $\\mathbf{w}$ and $b$, starting with some initial values. First we must compute the partial derivatives:\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{w_j} = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})- y^{(i)})x^{(i)}_j$$\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{b} = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})- y^{(i)})$$\n",
    "\n",
    "for  $j=1,...,n$  where  $n$  is the number of features\n",
    "\n",
    "Using the partials, we can repeat the following until convergence:\n",
    "\n",
    "$$ w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$$\n",
    "$$ b= b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$$\n",
    "\n",
    "where $\\alpha$ is a constant determining step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07a7ab83-7d71-4d39-aa32-339b8f21da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "\n",
    "    m,n = X.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6267481e-9879-4b62-ac48-28266accedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "# We can choose functions as well as a variable to set the number of iterations we want to run\n",
    "    \n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    J = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)\n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        # Save cost at each iteration\n",
    "        J.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% 100 == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J[-1]:8.2f}   \")\n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10278e35-3c13-449d-87ac-16adea0cd176",
   "metadata": {},
   "source": [
    "## Initial Implementation\n",
    "We can input our test data to obtain optimal parameter values. We should also ensure that cost is always decreasing with more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a62d2c1-7653-4c08-9625-46e4d51e7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 44154.43   \n",
      "Iteration  100: Cost  1565.13   \n",
      "Iteration  200: Cost  1560.99   \n",
      "Iteration  300: Cost  1556.92   \n",
      "Iteration  400: Cost  1552.92   \n",
      "Iteration  500: Cost  1549.00   \n",
      "Iteration  600: Cost  1545.15   \n",
      "Iteration  700: Cost  1541.36   \n",
      "Iteration  800: Cost  1537.65   \n",
      "Iteration  900: Cost  1534.01   \n",
      "parameters found by gradient descent: b = 0.00, w = [ 2.54443890e-01 -1.51872883e-04 -5.74533712e-04 -5.63067399e-02] \n"
     ]
    }
   ],
   "source": [
    "# initialize parameters, iterations and learning rate\n",
    "initial_w = np.zeros(4,)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 1.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final = gradient_descent(X, y, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"parameters found by gradient descent: b = {b_final:0.2f}, w = {w_final} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbb148-c1c0-4b44-b697-81b2a5d2c641",
   "metadata": {},
   "source": [
    "## Z-score normalisation\n",
    "\n",
    "In order to improve efficiency of our model, we can apply z-score normalisation to each parameter. To implement z-score normalization, we can use this formula:\n",
    "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} \\tag{4}$$ \n",
    "where $j$ represents features. $\\mu_j$ and $\\sigma_j$ are the mean and the standard deviation of feature $j$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cfa43dc-eb62-44ef-8f6a-c4b9b42e5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZSNorm(X):\n",
    "    \n",
    "    mu     = np.mean(X, axis=0)\n",
    "    sigma  = np.std(X, axis=0)     \n",
    "    \n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44bbebfe-6b99-45dc-a690-3d366680184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 57326.42   \n",
      "Iteration  100: Cost   221.73   \n",
      "Iteration  200: Cost   219.71   \n",
      "Iteration  300: Cost   219.71   \n",
      "Iteration  400: Cost   219.71   \n",
      "Iteration  500: Cost   219.71   \n",
      "Iteration  600: Cost   219.71   \n",
      "Iteration  700: Cost   219.71   \n",
      "Iteration  800: Cost   219.71   \n",
      "Iteration  900: Cost   219.71   \n",
      "parameters found by gradient descent after normalisation: b = 362.24, w = [110.61335173 -21.47323884 -32.66070323 -37.77938362] \n"
     ]
    }
   ],
   "source": [
    "X_ZSNorm, X_mu, X_sigma = ZSNorm(X)\n",
    "initial_w = np.zeros(4,)\n",
    "initial_b = 0.\n",
    "iterations = 1000\n",
    "alpha = 1.0e-1 # we are able to use a much larger learning rate after normalisation\n",
    "w_norm, b_norm = gradient_descent(X_ZSNorm, y, initial_w, initial_b,\n",
    "                                                    compute_cost, compute_gradient, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"parameters found by gradient descent after normalisation: b = {b_norm:0.2f}, w = {w_norm} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f7dd0-2ea6-4533-9591-a263bba94322",
   "metadata": {},
   "source": [
    "We can see that after normalisation, we can increase the learning rate, allowing the algorithm to converge to the lowest cost before even the 200th iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2246bc-ecbd-4532-888e-dcf2ab81b46c",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "We can now use the model trained on this dataset to predict the price of a house using its features. Suppose we want to consider a house which has area 1340sqft, has 4 bedrooms, 2 floors and is 16 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d485cee2-41f4-4dd7-9c8a-4d71b80176b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted price of a house with 1340 sqft, 4 bedrooms, 2 floors, 16 years old = $291480\n"
     ]
    }
   ],
   "source": [
    "# First, normalize out example\n",
    "x_house = np.array([1340, 4, 2, 16])\n",
    "x_house_norm = (x_house - X_mu) / X_sigma\n",
    "x_house_predict = np.dot(x_house_norm, w_norm) + b_norm\n",
    "print(f\" predicted price of a house with 1340 sqft, 4 bedrooms, 2 floors, 16 years old = ${x_house_predict*1000:0.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3736b-9a75-4ddd-b78d-c601f118b835",
   "metadata": {},
   "source": [
    "## Scikit Learn\n",
    "\n",
    "Finally, we use Scikit Learn to normalize and perform gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27dbb743-99a8-4139-87ae-b18f88033172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit learn model parameters: w = [110.15324212 -21.2043253  -32.37601808 -37.84995977], b = [362.22575239]\n",
      "previous model parameters: w = [110.61335173 -21.47323884 -32.66070323 -37.77938362], b = 362.2395199999998\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "sgdr = SGDRegressor(max_iter=1000)\n",
    "sgdr.fit(X_norm, y)\n",
    "b_sk = sgdr.intercept_\n",
    "w_sk = sgdr.coef_\n",
    "print(f\"scikit learn model parameters: w = {w_sk}, b = {b_sk}\")\n",
    "print(f\"previous model parameters: w = {w_norm}, b = {b_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79567c42-92d2-4450-a40b-f1de4b9c5b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
